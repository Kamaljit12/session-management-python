{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69183be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea18e53",
   "metadata": {},
   "source": [
    "# Session management testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db291c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for session ID\n",
    "class SessionId(BaseModel):\n",
    "    session_id: str = \"defauld-chat-session\"\n",
    "\n",
    "\n",
    "# session_id = SessionId(session_id = uuid.uuid4().hex).session_id\n",
    "session_state = set()\n",
    "\n",
    "# created sesion_id\n",
    "session_id = SessionId(session_id = uuid.uuid4().hex).session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424f93e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2ff2ee1bdcb0435a9a9829e855d066f3'}\n"
     ]
    }
   ],
   "source": [
    "if session_id not in session_state:\n",
    "    session_state.add(session_id)\n",
    "\n",
    "print(session_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b51312",
   "metadata": {},
   "source": [
    "# Session management in chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "158f625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for chat request\n",
    "class ChatRequest(BaseModel):\n",
    "    message: str\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6af248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple chatbot\n",
    "\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Groq API client using your API key\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "def simple_bot(state: ChatRequest) -> str:\n",
    "\n",
    "    # if SessionId.session_id not in session_state:\n",
    "    \n",
    "    query = state.message\n",
    "    # Create a simple but context-aware prompt\n",
    "    prompt = f\"Answer the following user query clearly and concisely:\\n\\n{query}\"\n",
    "\n",
    "    # Send request to Groq model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    # Extract and return response text\n",
    "    response_text = response.choices[0].message.content.strip()\n",
    "    return ChatResponse(response=response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa712cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatRequest(message='What is the capital of India?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = ChatRequest(message=\"What is the capital of India?\")\n",
    "user_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73edb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(response='The capital of India is New Delhi.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_bot(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad6486",
   "metadata": {},
   "source": [
    "# Building a conversational app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f126e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "from typing import Dict\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "from groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3125fac",
   "metadata": {},
   "source": [
    "### Define models and session storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a355a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pydantic models ---\n",
    "class ChatRequest(BaseModel):\n",
    "    session_id: str = None  # Optional, if not provided, create new\n",
    "    message: str\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    session_id: str\n",
    "    history: list  # List of {\"role\": str, \"content\": str}\n",
    "\n",
    "# --- Session management ---\n",
    "# session_store maps session_id -> ConversationBufferMemory\n",
    "session_store: Dict[str, ConversationBufferMemory] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a721df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groq llm client\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb158e6",
   "metadata": {},
   "source": [
    "### Groq wrapper to work with LangChain memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafc7f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groq_chat(messages: list) -> str:\n",
    "\n",
    "    # if SessionId.session_id not in session_state:\n",
    "    \n",
    "    # Create a simple but context-aware prompt\n",
    "    prompt = f\"Answer the following user query clearly and concisely:\\n\\n{messages}\"\n",
    "\n",
    "    # Send request to Groq model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    # Extract and return response text\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ffdb317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_chat(messages=[\"what is the capital of India?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ef1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "CHAT_DIR = \"chat_sessions\"\n",
    "os.makedirs(CHAT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Helper: save session to disk ---\n",
    "def save_session(session_id: str, memory: ConversationBufferMemory):\n",
    "    filepath = os.path.join(CHAT_DIR, f\"{session_id}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump([msg.dict() for msg in memory.chat_memory.messages], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b4f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper: load session from disk ---\n",
    "def load_session(session_id: str) -> ConversationBufferMemory:\n",
    "    filepath = os.path.join(CHAT_DIR, f\"{session_id}.json\")\n",
    "    memory = ConversationBufferMemory(return_messages=True)\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            messages = json.load(f)\n",
    "            for msg in messages:\n",
    "                if msg[\"type\"] == \"human\":\n",
    "                    memory.chat_memory.add_user_message(msg[\"content\"])\n",
    "                else:\n",
    "                    memory.chat_memory.add_ai_message(msg[\"content\"])\n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6add8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Memory Management ---\n",
    "# In-memory active sessions\n",
    "active_sessions: Dict[str, ConversationBufferMemory] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c240658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c5a7b75a2d5043a68c2d9acfee7b032f'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_id = str(uuid.uuid4().hex)\n",
    "session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18b9d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chatbot function ---\n",
    "def chat_bot(request: ChatRequest, save_after_chat: bool = False) -> ChatResponse:\n",
    "    # --- Load or create session ---\n",
    "    if not request.session_id:\n",
    "        session_id = uuid.uuid4().hex\n",
    "        memory = ConversationBufferMemory(return_messages=True)\n",
    "    else:\n",
    "        session_id = request.session_id\n",
    "        memory = active_sessions.get(session_id)\n",
    "        if not memory:\n",
    "            # Load from disk if available\n",
    "            memory = load_session(session_id)\n",
    "\n",
    "    # --- Add user message ---\n",
    "    memory.chat_memory.add_user_message(request.message)\n",
    "\n",
    "    # --- Prepare messages for Groq ---\n",
    "    messages_list = [\n",
    "        {\"role\": \"user\" if msg.type == \"human\" else \"assistant\", \"content\": msg.content}\n",
    "        for msg in memory.chat_memory.messages\n",
    "    ]\n",
    "\n",
    "    # --- Get assistant response ---\n",
    "    assistant_reply = groq_chat(messages_list)\n",
    "    memory.chat_memory.add_ai_message(assistant_reply)\n",
    "\n",
    "    # --- Update active sessions ---\n",
    "    active_sessions[session_id] = memory\n",
    "\n",
    "    # --- Optionally save session to disk ---\n",
    "    if save_after_chat:\n",
    "        save_session(session_id, memory)\n",
    "        active_sessions.pop(session_id, None)  # remove from active sessions\n",
    "\n",
    "    return ChatResponse(session_id=session_id, history=messages_list + [{\"role\": \"assistant\", \"content\": assistant_reply}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59420f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e8e2014984a84abcb4a60c8d9937a27a [{'role': 'user', 'content': 'Hello!'}, {'role': 'assistant', 'content': 'Hello. How can I assist you today?'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74205/2908949389.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# Start new session\n",
    "req1 = ChatRequest(message=\"Hello!\")\n",
    "res1 = chat_bot(req1)\n",
    "print(res1.session_id, res1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f82bbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e8e2014984a84abcb4a60c8d9937a27a': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello!', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello. How can I assist you today?', additional_kwargs={}, response_metadata={})]), return_messages=True)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb9a7465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello!', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello. How can I assist you today?', additional_kwargs={}, response_metadata={})]), return_messages=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sessions['e8e2014984a84abcb4a60c8d9937a27a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b665a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c69eab8f",
   "metadata": {},
   "source": [
    "### Chatbot function with memory and sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055b5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff430b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e6ac0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot(request: ChatRequest) -> ChatResponse:\n",
    "\n",
    "    # --- 1. Handle session ---\n",
    "    if not request.session_id:\n",
    "        # Create new session\n",
    "        session_id = uuid.uuid4().hex\n",
    "        memory = ConversationBufferMemory(return_messages=True)\n",
    "        session_store[session_id] = memory\n",
    "    else:\n",
    "        session_id = request.session_id\n",
    "        memory = session_store.get(session_id)\n",
    "        if memory is None:\n",
    "            # Create a new memory if session_id not found\n",
    "            memory = ConversationBufferMemory(return_messages=True)\n",
    "            session_store[session_id] = memory\n",
    "\n",
    "    # --- 2. Add user message to memory ---\n",
    "    memory.chat_memory.add_user_message(request.message)\n",
    "\n",
    "    # --- 3. Get full chat history for Groq -\n",
    "    messages_list = [\n",
    "    {\"role\": \"user\" if msg.type == \"human\" else \"assistant\", \"content\": msg.content}\n",
    "    for msg in memory.chat_memory.messages\n",
    "    ]\n",
    "    # --- 4. Get assistant response ---\n",
    "    assistant_reply = groq_chat(messages_list)\n",
    "\n",
    "    # --- 5. Save assistant reply to memory ---\n",
    "    memory.chat_memory.add_ai_message(assistant_reply)\n",
    "\n",
    "    # --- 6. Return response with session_id ---\n",
    "    return ChatResponse(session_id=session_id, history=messages_list + [{\"role\": \"assistant\", \"content\": assistant_reply}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cee739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15f760738ac543e583a0aedd77766a2b [{'role': 'user', 'content': 'my name is kamal!'}, {'role': 'assistant', 'content': 'Nice to meet you, Kamal. How can I assist you today?'}]\n"
     ]
    }
   ],
   "source": [
    "# New conversation\n",
    "req1 = ChatRequest(message=\"my name is kamal!\")\n",
    "res1 = chat_bot(req1)\n",
    "print(res1.session_id, res1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f2d31c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15f760738ac543e583a0aedd77766a2b'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "87fa612a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'my name is kamal!'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Nice to meet you, Kamal. How can I assist you today?'}]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eea000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "06941170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_store['6a983f763aa840f4a52fd0764edf60ec'].chat_memory.messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf77e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5840bdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, how can I assist you today?'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_store['6a983f763aa840f4a52fd0764edf60ec'].chat_memory.messages[1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
