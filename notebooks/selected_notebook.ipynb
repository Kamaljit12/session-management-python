{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7826dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Dict\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# groq llm client\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bab0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groq_chat(messages: list) -> str:\n",
    "\n",
    "    # if SessionId.session_id not in session_state:\n",
    "    \n",
    "    # Create a simple but context-aware prompt\n",
    "    prompt = f\"Answer the following user query clearly and concisely:\\n\\n{messages}\"\n",
    "\n",
    "    # Send request to Groq model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    # Extract and return response text\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "606a5433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_chat(messages=[\"what is the capital of India?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa7ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatRequest(BaseModel):\n",
    "    query: str\n",
    "    session_id: str = None\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "    session_id: str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb91eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Memory Management ---\n",
    "# In-memory active sessions\n",
    "active_sessions: Dict[str, ConversationBufferMemory] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f741bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad2cf59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Session filter/create function ---\n",
    "def filter_or_create_session_id(session_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Ensures session_id exists in active_sessions.\n",
    "    If not, creates a new one with ConversationBufferMemory.\n",
    "    \"\"\"\n",
    "\n",
    "    if session_id not in active_sessions:\n",
    "        session_id = str(uuid.uuid4().hex)\n",
    "        active_sessions[session_id] = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "        print(f\"ðŸ†• Created new session: {session_id}\")\n",
    "    else:\n",
    "        print(f\"âœ… Using existing session: {session_id}\")\n",
    "\n",
    "    return session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb88979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ†• Created new session: 7cdaca33589344f38259f96b84615d87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7064\\176814929.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  active_sessions[session_id] = ConversationBufferMemory(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7cdaca33589344f38259f96b84615d87'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_or_create_session_id(session_id=\"ajhflksjloejojposgsg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23b6d709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7cdaca33589344f38259f96b84615d87': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af4aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# ===============m Filter or create session id ========================\n",
    "def filter_or_create_session_id(session_id: str) -> str:\n",
    "\n",
    "    if session_id not in active_sessions:\n",
    "        # Create new session\n",
    "        session_id = str(uuid.uuid4().hex)\n",
    "        active_sessions[session_id] = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    else:\n",
    "        # Use existing session\n",
    "        return session_id\n",
    "    \n",
    "# filter or create sesison id\n",
    "filtered_session_id = filter_or_create_session_id(session_id=\"fda9441bb78e46a79398ff0095cc8593\")\n",
    "print(filtered_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0179c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7cdaca33589344f38259f96b84615d87': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history'),\n",
       " '195c3d45f54a47bebdcfa002e8ed6ec4': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f87b898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_id = \"fda9441bb78e46a79398ff0095cc8593\"\n",
    "\n",
    "# if filter_or_create_session_id(SessionId(session_id=session_id)):\n",
    "#     print(session_id)\n",
    "# else:\n",
    "#     print(\"created session id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4eeaef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(query: str) -> str:\n",
    "    \n",
    "    # Create a simple but context-aware prompt\n",
    "    prompt = f\"Answer the following user query clearly and concisely:\\n\\n{query}\"\n",
    "\n",
    "    # Send request to Groq model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    # Extract and return response text\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01aa8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "response = chatbot(query=\"what is the capital of India?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f6efc",
   "metadata": {},
   "source": [
    "<!-- ### Now manage the session with memeory in chatbot -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32d81e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7cdaca33589344f38259f96b84615d87': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history'),\n",
       " '195c3d45f54a47bebdcfa002e8ed6ec4': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history')}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b79120f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created session id\n"
     ]
    }
   ],
   "source": [
    "session_id = \"fda9441bb78e46a79398ff0095cc8593\"\n",
    "\n",
    "if filter_or_create_session_id(session_id=session_id):\n",
    "    print(session_id)\n",
    "else:\n",
    "    print(\"created session id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a791088e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7cdaca33589344f38259f96b84615d87': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history'),\n",
       " '195c3d45f54a47bebdcfa002e8ed6ec4': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history'),\n",
       " 'f9329964da4141eba03f1db9214b4242': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c23e1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatRequest(BaseModel):\n",
    "    query: str\n",
    "    session_id: str = None  # Optional, if not provided, create new\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    session_id: str = None  # Return session_id in response\n",
    "    history: list = []  # Chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec5125e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseChatMessageHistory.add_ai_message of InMemoryChatMessageHistory(messages=[])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sessions['7cdaca33589344f38259f96b84615d87'].chat_memory.add_user_message\n",
    "active_sessions['7cdaca33589344f38259f96b84615d87'].chat_memory.add_ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29f3c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chatbot function with conversation memory ---\n",
    "def chat_with_memory(state: ChatRequest) -> ChatResponse:\n",
    "    \"\"\"\n",
    "    Manage conversational chat sessions with memory.\n",
    "    Creates or reuses a session and keeps conversation context.\n",
    "    \"\"\"\n",
    "    # 1. Ensure session exists\n",
    "    session_id = filter_or_create_session_id(session_id=state.session_id)\n",
    "    memory = active_sessions[session_id]\n",
    "\n",
    "    # 2. Add user message to memory\n",
    "    memory.chat_memory.add_user_message(state.query)\n",
    "\n",
    "    # 3. Convert chat memory to Groq messages format\n",
    "    messages_for_groq = [\n",
    "        {\"role\": \"user\" if msg.type == \"human\" else \"assistant\", \"content\": msg.content}\n",
    "        for msg in memory.chat_memory.messages]\n",
    "\n",
    "    # 4. Get response from Groq model\n",
    "    assistant_reply = chatbot(query=messages_for_groq)\n",
    "\n",
    "    # 5. Add assistant reply to memory\n",
    "    memory.chat_memory.add_ai_message(assistant_reply)\n",
    "\n",
    "    # 6. Prepare history for response\n",
    "    chat_history = [\n",
    "        {\"role\": \"user\" if msg.type == \"human\" else \"assistant\", \"content\": msg.content}\n",
    "        for msg in memory.chat_memory.messages\n",
    "    ]\n",
    "    \n",
    "    # 7. Return response\n",
    "    return ChatResponse(session_id=session_id, history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "915de234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatRequest(query='hello my name is jeet', session_id='7cdaca33589344f38259f96b84615d87')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = ChatRequest(**{\"query\": \"hello my name is jeet\", \"session_id\": \"7cdaca33589344f38259f96b84615d87\"})\n",
    "initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9667381",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_with_memory(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e878f646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'hello my name is jeet'},\n",
       " {'role': 'assistant', 'content': 'Hello Jeet. How can I assist you today?'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b75da9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'hello my name is jeet'}, {'role': 'assistant', 'content': 'Hello Jeet. How can I assist you today?'}, {'role': 'user', 'content': 'what is my name?'}, {'role': 'assistant', 'content': 'Hello Jeet. Your name is Jeet.'}]\n"
     ]
    }
   ],
   "source": [
    "initial_state = ChatRequest(**{\"query\": \"what is my name?\", \"session_id\": \"7cdaca33589344f38259f96b84615d87\"})\n",
    "response = chat_with_memory(initial_state)\n",
    "print(response.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33cb732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'hello my name is jeet'}, {'role': 'assistant', 'content': 'Hello Jeet. How can I assist you today?'}, {'role': 'user', 'content': 'what is my name?'}, {'role': 'assistant', 'content': 'Hello Jeet. Your name is Jeet.'}, {'role': 'user', 'content': 'what did i ask just before?'}, {'role': 'assistant', 'content': 'You asked \"what is my name?\" just before.'}]\n"
     ]
    }
   ],
   "source": [
    "initial_state = ChatRequest(**{\"query\": \"what did i ask just before?\", \"session_id\": \"7cdaca33589344f38259f96b84615d87\"})\n",
    "response = chat_with_memory(initial_state)\n",
    "print(response.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "849f3709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'hello my name is jeet'}\n",
      "{'role': 'assistant', 'content': 'Hello Jeet. How can I assist you today?'}\n",
      "{'role': 'user', 'content': 'what is my name?'}\n",
      "{'role': 'assistant', 'content': 'Hello Jeet. Your name is Jeet.'}\n",
      "{'role': 'user', 'content': 'what did i ask just before?'}\n",
      "{'role': 'assistant', 'content': 'You asked \"what is my name?\" just before.'}\n"
     ]
    }
   ],
   "source": [
    "for msg in response.history:\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
